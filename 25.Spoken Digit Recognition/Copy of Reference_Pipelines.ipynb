{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Copy of Reference_Pipelines.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"bLNQGqpGk5E5"},"source":["import tensorflow as tf\n","# tf.enable_eager_execution()\n","import os\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt\n","# from hilbert import hilbertCurve\n","import imgaug.augmenters as iaa\n","import numpy as np\n","# import albumentations as A\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loadqWrCk5FP"},"source":["#!pip install imgaug"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8ucs8gJk5FU"},"source":["from tensorflow.keras.layers import Flatten"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jgowa558k5Fa"},"source":["# here dir_path is the route directory where all the images and segmentation maps are there\n","dir_path = \"900_images\"\n","file_names = set()\n","for i in os.listdir(dir_path):\n","    file_names.add(i.split('.')[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1_bloVMk5Fg"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test = train_test_split(list(file_names), test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BHGkhg9Qk5F7"},"source":["# import imgaug.augmenters as iaa\n","# For the assignment choose any 4 augumentation techniques\n","# check the imgaug documentations for more augmentations\n","aug2 = iaa.Fliplr(1)\n","aug3 = iaa.Flipud(1)\n","aug4 = iaa.Emboss(alpha=(1), strength=1)\n","aug5 = iaa.DirectedEdgeDetect(alpha=(0.8), direction=(1.0))\n","aug6 = iaa.Sharpen(alpha=(1.0), lightness=(1.5))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Zu_VL0ak5GE"},"source":["def visualize(**images):\n","    n = len(images)\n","    plt.figure(figsize=(16, 5))\n","    for i, (name, image) in enumerate(images.items()):\n","        plt.subplot(1, n, i + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.title(' '.join(name.split('_')).title())\n","        if i==1:\n","            plt.imshow(image, cmap='gray', vmax=1, vmin=0)\n","        else:\n","            plt.imshow(image)\n","    plt.show()\n","    \n","def normalize_image(mask):\n","    mask = mask/255\n","    return mask\n","\n","class Dataset:\n","    # we will be modifying this CLASSES according to your data/problems\n","    CLASSES = ['edited','non-edited']\n","    \n","    # the parameters needs to changed based on your requirements\n","    # here we are collecting the file_names because in our dataset, both our images and maks will have same file name\n","    # ex: fil_name.jpg   file_name.mask.jpg\n","    def __init__(self, images_dir, file_names):\n","        \n","        self.ids = file_names\n","        # the paths of images\n","        self.images_fps   = [os.path.join(images_dir, image_id+'.jpg') for image_id in self.ids]\n","        # the paths of segmentation images\n","        self.masks_fps    = [os.path.join(images_dir, image_id+\".mask.jpg\") for image_id in self.ids]\n","        # giving labels for each class\n","        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n","    \n","    def __getitem__(self, i):\n","        \n","        # read data\n","        image = cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED)\n","        mask  = cv2.imread(self.masks_fps[i], cv2.IMREAD_UNCHANGED)\n","        image_mask = normalize_image(mask)\n","\n","        \n","        image_masks = [(image_mask == v) for v in self.class_values]\n","        image_mask = np.stack(image_masks, axis=-1).astype('float')\n","   \n","        a = np.random.uniform()\n","        if a<0.2:\n","            image = image\n","            image_mask = image_mask\n","        elif a<0.4:\n","            image = aug3.augment_image(image)\n","            image_mask = aug3.augment_image(image_mask)\n","        elif a<0.6:\n","            image = aug4.augment_image(image)\n","            image_mask = aug4.augment_image(image_mask)\n","        elif a<0.8:\n","            image = aug5.augment_image(image)\n","            image_mask = image_mask\n","        else:\n","            image = aug6.augment_image(image)\n","            image_mask = aug6.augment_image(image_mask)\n","            \n","        return image, image_mask\n","        \n","    def __len__(self):\n","        return len(self.ids)\n","    \n","    \n","class Dataloder(tf.keras.utils.Sequence):    \n","    def __init__(self, dataset, batch_size=1, shuffle=False):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.indexes = np.arange(len(dataset))\n","\n","    def __getitem__(self, i):\n","        \n","        # collect batch data\n","        start = i * self.batch_size\n","        stop = (i + 1) * self.batch_size\n","        data = []\n","        for j in range(start, stop):\n","            data.append(self.dataset[j])\n","        \n","        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n","        \n","        return tuple(batch)\n","    \n","    def __len__(self):\n","        return len(self.indexes) // self.batch_size\n","    \n","    def on_epoch_end(self):\n","        if self.shuffle:\n","            self.indexes = np.random.permutation(self.indexes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2OIB-he-k5GP","outputId":"73bc0da1-a50a-4f3e-bfac-f45c5764f3f5"},"source":["# Dataset for train images\n","CLASSES = ['edited']\n","train_dataset = Dataset(dir_path,X_train, classes=CLASSES)\n","test_dataset  = Dataset(dir_path,X_test, classes=CLASSES)\n","\n","\n","train_dataloader = Dataloder(train_dataset, batch_size=1, shuffle=True)\n","test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=True)\n","\n","print(train_dataloader[0][0].shape)\n","assert train_dataloader[0][0].shape == (BATCH_SIZE, 512, 512, 3)\n","assert train_dataloader[0][1].shape == (BATCH_SIZE, 512, 512, 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 512, 512, 3)\n"],"name":"stdout"}]}]}